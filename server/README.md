# FastAPI RAG Server

This project is a FastAPI server that provides an API for handling PDF file uploads and answering questions using LangChain's Retrieval-Augmented Generation (RAG) capabilities. It uses a PostgreSQL vector database (PGVector) for storing and retrieving embeddings of uploaded documents, and OpenAI’s GPT model for generating answers based on the retrieved data. This server could serve as a backend for an AI-powered application that allows users to upload documents and ask questions related to those documents.

## Features

-   **File Uploads**: Users can upload PDF files, which are processed and stored in the PGVector database with user-specific metadata.
-   **Question-Answering**: Users can query the documents they uploaded. The server uses OpenAI's GPT-3.5-turbo model and embeddings for context-based question answering.
-   **User-Specific Storage**: Each uploaded document is stored with a `user_id` to allow user-specific document retrieval and filtering.

## Requirements

-   Python 3.8 or higher
-   PostgreSQL with the [PGVector extension](https://github.com/pgvector/pgvector) installed
-   An OpenAI API key

## Setup Instructions

### 1. Clone the repository

```bash
git clone <repository-url>
cd <repository-directory>
```

### 2. Install dependencies

Install Python dependencies from `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 3. Environment variables

Create a `.env` file in the project root and configure the following environment variables:

```plaintext
# Database configuration
CONNECTION_STRING=postgresql://<username>:<password>@<host>:<port>/<database_name>

# Vector store configuration
COLLECTION_NAME=your_vector_collection_name

# OpenAI API Key
OPENAI_API_KEY=your_openai_api_key
```

### 4. Run the server

To start the FastAPI server, run:

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Or run it with the `__main__` entry point:

```bash
python app/main.py
```

The server will be accessible at `http://localhost:8000`.

## API Documentation

FastAPI automatically generates interactive API documentation at:

-   Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)
-   Redoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### Endpoints

#### 1. **Upload PDF**

Uploads a PDF file for a specific user.

-   **URL**: `/upload/{user_id}`
-   **Method**: `POST`
-   **Path Parameter**:
    -   `user_id` (str): Unique identifier for the user uploading the file.
-   **Body Parameter**:
    -   `file` (UploadFile): The PDF file to upload.
-   **Response**: Returns the file path where the file is saved.
-   **Example Request**:

    ```bash
    curl -X POST "http://localhost:8000/upload/user123" -F "file=@example.pdf"
    ```

-   **Example Response**:

    ```json
    {
    	"file_path": "data/user123/example.pdf"
    }
    ```

#### 2. **Query RAG (Question-Answering)**

Allows a user to ask questions based on their uploaded documents.

-   **URL**: `/query/{user_id}`
-   **Method**: `POST`
-   **Path Parameter**:
    -   `user_id` (str): Unique identifier for the user making the query.
-   **Body Parameters**:
    -   `question` (str): The question to ask.
    -   `chat_history` (list): List of previous questions and answers for context.
-   **Response**: Returns an answer generated by the language model based on the user's documents.
-   **Example Request**:

    ```json
    POST /query/user123
    {
      "question": "Explain the main topic of the document.",
      "chat_history": [
        {
          "question": "What is the document about?",
          "answer": "It covers various aspects of AI development."
        }
      ]
    }
    ```

-   **Example Response**:

    ```json
    {
    	"answer": "The document discusses the latest advancements in AI."
    }
    ```

## Project Structure

```plaintext
app/
├── api/
│   └── routes.py          # Defines the API routes and endpoints
├── services/
│   ├── upload_service.py   # Handles file upload logic
│   └── langchain_service.py # Handles the question-answering logic using LangChain
├── main.py                 # Main FastAPI application setup
.env                        # Environment variables file
requirements.txt            # Python dependencies
README.md                   # Documentation
```

## Brief Overview

This server has two main services:

1. **File Upload Service**: Manages the upload of PDF files by users. The files are stored in a user-specific directory, and document embeddings are generated and stored in a PGVector collection for fast retrieval.

2. **Question-Answering Service**: Uses LangChain's Retrieval-Augmented Generation (RAG) chain, combining the OpenAI language model and the PGVector retrieval database. This service takes user-specific documents and a question as input, retrieves relevant document sections, and generates an answer.

## Logging and Error Handling

-   The server includes basic logging to help with debugging and monitoring.
-   Errors are handled by returning HTTP 500 status codes and detailed error messages where applicable.
